{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "920ef7bb-0e31-4151-9fb0-50de1141d91e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ffe1f7f4ada8c4a3160626f214fc1e36",
     "grade": false,
     "grade_id": "cell-48cccda20e73351e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Hackathon: From Raw Data to ML-Ready Dataset\n",
    "## Insight-Driven EDA and End-to-End Feature Engineering on Airbnb Data Using pandas and Plotly\n",
    "\n",
    "### What is a Hackathon?\n",
    "\n",
    "A hackathon is a fast-paced, collaborative event where participants use data and technology to solve a real problem end-to-end.  \n",
    "In this hackathon, you will work with a **real-world Airbnb dataset** and complete two interconnected goals:\n",
    "\n",
    "- Produce a **high-quality exploratory data analysis (EDA)** using `pandas` and `plotly`, extracting meaningful insights, trends, and signals from the data.  \n",
    "- Design and deliver a **clean, feature-rich, ML-ready dataset** that will serve as the foundation for a follow-up hackathon focused on building and evaluating machine learning models.\n",
    "\n",
    "Your task is to **get the most out of the data**: uncover structure and patterns through EDA, and engineer informative features (numerical, categorical, temporal, textual (TF–IDF), and optionally image-based) to maximize the predictive power of the final dataset.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>About the Dataset</b>\n",
    "\n",
    "<u>Context</u>\n",
    "\n",
    "The data comes from <a href=\"https://insideairbnb.com/get-the-data/\">Inside Airbnb</a>, an open project that publishes detailed, regularly updated datasets for cities around the world.  \n",
    "Each city provides three main CSV files:\n",
    "\n",
    "- <b>listings.csv</b> — property characteristics, host profiles, descriptions, amenities, etc.  \n",
    "- <b>calendar.csv</b> — daily availability and pricing information for each listing.  \n",
    "- <b>reviews.csv</b> — guest feedback and textual reviews.\n",
    "\n",
    "These datasets offer a rich view of the short-term rental market, including availability patterns, pricing behavior, host attributes, and guest sentiment.  \n",
    "\n",
    "<u>Inspiration</u>\n",
    "\n",
    "Your ultimate objective is to create a dataset suitable for training a machine learning model that predicts whether a specific Airbnb listing will be <b>available on a given date</b>, using property attributes, review information, and host characteristics.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Task</b>\n",
    "\n",
    "Using one city of your choice from Inside Airbnb, create an end-to-end pipeline that:\n",
    "\n",
    "1. Loads and explores the raw data (EDA).  \n",
    "2. Engineers features (numerical, categorical, temporal, textual TF–IDF, etc.).  \n",
    "3. Builds a unified ML-ready dataset.  \n",
    "\n",
    "Please remember to add comments explaining your decisions. Comments help us understand your thought process and ensure accurate evaluation of your work. This assignment requires code-based solutions—**manually calculated or hard-coded results will not be accepted**. Thoughtful comments and visualizations are encouraged and will be highly valued.\n",
    "\n",
    "- Write your solution directly in this notebook, modifying it as needed.\n",
    "- Once completed, submit the notebook in **.ipynb** format via Moodle.\n",
    "    \n",
    "<b>Collaboration Requirement: Git & GitHub</b>\n",
    "\n",
    "You must collaborate with your team using a **shared GitHub repository**.  \n",
    "Your use of Git is part of the evaluation. We will specifically look at:\n",
    "\n",
    "- Commit quality (clear messages, meaningful steps).  \n",
    "- Balanced participation across team members.  \n",
    "- Use of branches.  \n",
    "- Ability to resolve merge conflicts appropriately.  \n",
    "- A clean, readable project history that reflects real collaboration.\n",
    "\n",
    "Good Git practice is **part of your grade**, not optional.\n",
    "</div>\n",
    "<div class=\"alert alert-danger\">\n",
    "    You are free to add as many cells as you wish as long as you leave untouched the first one.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Hints</b>\n",
    "\n",
    "- Text columns often carry substantial predictive power, use text-vectorization methods to extract meaningful features.  \n",
    "- Make sure all columns use appropriate data types (categorical, numeric, datetime, boolean). Correct dtypes help prevent subtle bugs and improve performance.  \n",
    "- Feel free to enrich the dataset with any additional information you consider useful: engineered features, external data, derived temporal features, etc.  \n",
    "- If the dataset is too large for your computer, use <code>.sample()</code> to work with a subset while preserving the logic of your pipeline.  \n",
    "- Plotly offers a wide variety of powerful visualizations, experiment creatively, but always begin with a clear analytical question: *What insight am I trying to uncover with this plot?*\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "<b>Submission Deadline:</b> Wednesday, December 3rd, 12:00\n",
    "\n",
    "Start with a simple, working pipeline.  \n",
    "Do not over-complicate your code too much. Start with a simple working solution and refine it if you have time.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "    \n",
    "You may add as many cells as you want, but the **first cell must remain exactly as provided**. Do not edit, move, or delete it under any circumstances.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da41098",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8431230dc8647851888c39d82eb7078d",
     "grade": true,
     "grade_id": "ex1",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# LEAVE BLANK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84467c34-1fa2-4f03-b7ba-e216836ff6b3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7bce797b7aa5f22189e671fd29fa5841",
     "grade": false,
     "grade_id": "cell-140b4c12d85796ac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Team Information\n",
    "\n",
    "Fill in the information below.  \n",
    "All fields are **mandatory**.\n",
    "\n",
    "- **GitHub Repository URL**: Paste the link to the team repo you will use for collaboration.\n",
    "- **Team Members**: List all student names (and emails or IDs if required).\n",
    "\n",
    "Do not modify the section title.  \n",
    "Do not remove this cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907a430c-3e17-42e4-9b63-3bafd596c383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Team Information (Mandatory) ===\n",
    "# Fill in the fields below.\n",
    "\n",
    "GITHUB_REPO = \"https://github.com/MateoBarredaR/hackaton1\"    \n",
    "TEAM_MEMBERS = [\n",
    "     \"Mateo Barreda\",\n",
    "     \"Jerico Agdan\",\n",
    "     \"Warren Liu\",\n",
    "     \"Maryeme Idiata\",\n",
    "     \"María Mora\"\n",
    "]\n",
    "\n",
    "GITHUB_REPO, TEAM_MEMBERS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2a552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open files to check the data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "path = \"/Users/mariamorazamora/Downloads/\"\n",
    "\n",
    "reviews = pd.read_csv(path + \"reviews.csv\")\n",
    "calendar = pd.read_csv(path + \"calendar.csv\")\n",
    "listings = pd.read_csv(path + \"listings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60172100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data\n",
    "\n",
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a964f8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c26614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9023f54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN values\n",
    "\n",
    "reviews.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4237d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8493c33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "listings.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705645cc",
   "metadata": {},
   "source": [
    "**Justification for Dropping Columns**\n",
    "\n",
    "After analizing the data we decided that to build a clean and interpretable dataset for predicting whether a listing will be available on a given date, we decided to drop several columns from the original Airbnb files. The main reasons are:\n",
    "(1) they do not add predictive value,\n",
    "(2) they are leakage or duplicated information,\n",
    "(3) they are high-cardinality identifiers or URLs, or\n",
    "(4) they are long unstructured text fields that we will not process with NLP in this project.\n",
    "\n",
    "**Dropped columns from listings.csv**\n",
    "\n",
    "We removed multiple identifier and URL columns such as listing_url, host_url, picture_url, host_thumbnail_url, and host_picture_url. These variables uniquely identify listings or hosts but do not carry meaningful behavioral or structural information that could help predict daily availability. Keeping them would only increase dimensionality and risk overfitting without improving model performance.\n",
    "We also dropped scraping and update metadata like scrape_id, last_scraped, calendar_last_scraped, and calendar_updated. These fields describe when the data was collected rather than any intrinsic attribute of the property or host. As such, they reflect the data collection process instead of the booking dynamics we want to model.\n",
    "Several advanced availability and nights-rule columns (e.g. availability_30, availability_60, availability_365, minimum_minimum_nights, maximum_minimum_nights, minimum_maximum_nights, maximum_maximum_nights, minimum_nights_avg_ntm, maximum_nights_avg_ntm) were also removed. These variables summarize availability over future horizons and encode information that is very close to the target (whether the listing is available on a specific date). Using them could introduce information leakage, making the model unrealistically optimistic and less generalizable in a real-world setting.\n",
    "We further discarded some long free-text descriptions such as description, neighborhood_overview, host_about, and host_verifications. Although these fields might contain useful signals, exploiting them properly would require a dedicated NLP pipeline (tokenization, embeddings, etc.), which is beyond the scope of this exercise. Without that processing, they mostly introduce noise, memory usage, and complexity, so we chose to focus on structured numerical and categorical features instead.\n",
    "Finally, we removed a few low-quality or sparse variables, such as neighbourhood_group and license, which are either mostly missing or not consistently populated. Including them would not materially improve the predictive power of the model and could complicate the feature space with many missing values.\n",
    "\n",
    "**Dropped columns from reviews.csv**\n",
    "\n",
    "From reviews.csv, we dropped reviewer_id and reviewer_name, since they are pure identifiers of individual users and do not generalize beyond the specific dataset. We also decided not to use the raw comments field as a feature. As with the listing descriptions, this column is long unstructured text that would require additional NLP modeling. Instead, we plan to derive aggregate review-based features (such as number of reviews or average scores) at the listing level, which are more compact and easier to integrate in a standard machine-learning pipeline.\n",
    "\n",
    "**Dropped columns from calendar.csv**\n",
    "\n",
    "In calendar.csv, our main focus is on the daily availability flag. For that reason, we kept listing_id, date, and available as the core variables. Other columns, such as price and adjusted_price, may appear in string format and are often redundant with the price information already stored in listings.csv. To avoid inconsistencies and duplicated information, we rely on the cleaned numeric price from listings.csv and ignore the price fields in calendar.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c5f1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop in listings\n",
    "\n",
    "cols_to_drop_listings = [\n",
    "    # identifiers & URLs\n",
    "    \"listing_url\", \"scrape_id\", \"last_scraped\", \"picture_url\", \"host_url\",\n",
    "    \"host_thumbnail_url\", \"host_picture_url\",\n",
    "\n",
    "    # text-heavy fields\n",
    "    \"description\", \"neighborhood_overview\", \"host_about\", \"host_verifications\",\n",
    "\n",
    "    # leakage / future availability summaries\n",
    "    \"availability_30\", \"availability_60\", \"availability_365\",\n",
    "    \"calendar_last_scraped\", \"calendar_updated\",\n",
    "\n",
    "    # complex minimum/maximum night statistics\n",
    "    \"minimum_minimum_nights\", \"maximum_minimum_nights\",\n",
    "    \"minimum_maximum_nights\", \"maximum_maximum_nights\",\n",
    "    \"minimum_nights_avg_ntm\", \"maximum_nights_avg_ntm\",\n",
    "\n",
    "    # low-quality or sparse\n",
    "    \"neighbourhood_group\", \"license\"\n",
    "]\n",
    "\n",
    "listings_clean = listings.drop(columns=cols_to_drop_listings, errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d788f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop in reviews\n",
    "\n",
    "cols_to_drop_reviews = [\n",
    "    \"reviewer_id\",\n",
    "    \"reviewer_name\",\n",
    "    \"comments\"   # drop solo si NO vas a usar NLP\n",
    "]\n",
    "\n",
    "reviews_clean = reviews.drop(columns=cols_to_drop_reviews, errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4694ed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop in calendar\n",
    "\n",
    "cols_to_drop_calendar = [\n",
    "    \"price\",\n",
    "    \"adjusted_price\",\n",
    "    \"minimum_nights\",\n",
    "    \"maximum_nights\"\n",
    "]\n",
    "\n",
    "calendar_clean = calendar.drop(columns=cols_to_drop_calendar, errors=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5f3327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the remaining columns\n",
    "\n",
    "listings_clean.shape, reviews_clean.shape, calendar_clean.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c2309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the remaining NaN values\n",
    "\n",
    "calendar.isna().sum()\n",
    "listings.isna().sum()\n",
    "reviews.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2318a2",
   "metadata": {},
   "source": [
    "**Exploratory Data Analysis (EDA)**\n",
    "\n",
    "The goal of this step is to understand how property characteristics, host attributes, and review information relate to a listing’s daily availability. Since our final objective is to predict whether a listing is available on a specific date, visual exploration helps us identify meaningful patterns, detect noise, and decide which features are likely to be useful for the predictive model.\n",
    "\n",
    "1. Merge calendar and listings data\n",
    "To perform a meaningful EDA, we first merge the daily availability data from calendar with the listing-level attributes from listings_clean.\n",
    "This allows us to analyze how availability varies with price, room type, location, host characteristics, and other structural attributes.\n",
    "We first merge only the calendar and listings datasets because calendar contains the daily availability information, which defines the target granularity of the final dataset. Joining calendar with listings is a clean one-to-many merge (one listing → many dates).\n",
    "The reviews dataset cannot be merged directly because it would create a many-to-many explosion (multiple reviews per listing × multiple calendar dates per listing). Instead, we first aggregate the review information at the listing level and only then merge the aggregated features using the shared key listing_id.\n",
    "\n",
    "2. Target variable exploration\n",
    "We start by analyzing the distribution of our target variable (available, encoded as 0/1).\n",
    "This reveals whether the dataset is balanced and whether there are strong occupancy patterns throughout the year.\n",
    "Key insights we aim to identify:\n",
    "Are most listings available or booked?\n",
    "Is the target distribution extremely imbalanced?\n",
    "Do availability patterns follow seasonal trends?\n",
    "\n",
    "3. Temporal patterns\n",
    "Daily availability is strongly influenced by calendar dynamics (weekends, seasons, holidays).\n",
    "We extract time-based features such as month and day of week, and explore:\n",
    "Availability by month\n",
    "Availability by day of week\n",
    "Seasonal spikes or dips\n",
    "Peak vs. off-peak periods\n",
    "These visualizations help determine whether temporal features should be included in the predictive model.\n",
    "\n",
    "4. Listing characteristics and availability\n",
    "Next, we analyze how availability correlates with structural property features:\n",
    "Price\n",
    "Room type\n",
    "Number of bedrooms and beds\n",
    "Property type\n",
    "Location (neighbourhood)\n",
    "Latitude/Longitude\n",
    "Purpose of this analysis:\n",
    "Identify which features have a meaningful relationship with availability\n",
    "Detect noisy variables\n",
    "Highlight strong predictors (e.g., entire homes may book out more often than private rooms)\n",
    "\n",
    "5. Host characteristics and availability\n",
    "Host-related attributes often influence booking probability. We explore:\n",
    "Whether listings from superhosts have lower/higher availability\n",
    "Whether more experienced hosts (high listing count) show different patterns\n",
    "Response/acceptance rates\n",
    "Cancellation policies\n",
    "This helps clarify whether host behavior is an important predictor.\n",
    "\n",
    "6. Review-based signals\n",
    "Reviews provide important quality indicators.\n",
    "Even if we are not using full NLP, we can compute aggregated review features (count, average score) and examine their relationship with availability.\n",
    "For example:\n",
    "Do listings with many positive reviews tend to be booked more often?\n",
    "Is review volume correlated with occupancy?\n",
    "Does high cleanliness/accuracy score predict booking likelihood?\n",
    "These insights support the selection of meaningful, compact review features for modeling.\n",
    "\n",
    "7. Summary of EDA goals\n",
    "By the end of Step 2, the EDA should help us determine:\n",
    "Which features show clear patterns with availability\n",
    "Which variables appear noisy or irrelevant\n",
    "Which temporal variables to include\n",
    "Which listing, host, and review attributes have predictive power\n",
    "Which transformations or encodings will be needed for modeling\n",
    "This analysis guides the feature engineering step and ensures that the final dataset is both clean and informative for predicting Airbnb availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb21328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert date to datetime\n",
    "calendar_clean[\"date\"] = pd.to_datetime(calendar_clean[\"date\"], errors=\"coerce\")\n",
    "\n",
    "# Create binary target: 1 = available, 0 = not available\n",
    "# Airbnb calendar usually stores \"t\"/\"f\"\n",
    "calendar_clean[\"available_flag\"] = calendar_clean[\"available\"].map({\"t\": 1, \"f\": 0})\n",
    "\n",
    "# Drop rows where target is missing (if any)\n",
    "calendar_clean = calendar_clean.dropna(subset=[\"available_flag\"])\n",
    "calendar_clean[\"available_flag\"] = calendar_clean[\"available_flag\"].astype(int)\n",
    "\n",
    "base_df = calendar_clean.merge(\n",
    "    listings_clean,\n",
    "    left_on=\"listing_id\",\n",
    "    right_on=\"id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "w\n",
    "base_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed43f58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph target distribution\n",
    "\n",
    "# Value counts of the target\n",
    "print(base_df[\"available_flag\"].value_counts())\n",
    "print(base_df[\"available_flag\"].value_counts(normalize=True))\n",
    "\n",
    "# Plot distribution of the target\n",
    "plt.figure()\n",
    "base_df[\"available_flag\"].value_counts().sort_index().plot(kind=\"bar\")\n",
    "plt.xlabel(\"available_flag (0 = booked, 1 = available)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Target distribution: availability per day\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd6a970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph temporal patterns\n",
    "\n",
    "# Create temporal features\n",
    "base_df[\"month\"] = base_df[\"date\"].dt.month\n",
    "base_df[\"day_of_week\"] = base_df[\"date\"].dt.dayofweek  # 0 = Monday, 6 = Sunday\n",
    "\n",
    "# Availability by month\n",
    "availability_by_month = base_df.groupby(\"month\")[\"available_flag\"].mean()\n",
    "print(availability_by_month)\n",
    "\n",
    "plt.figure()\n",
    "availability_by_month.plot(kind=\"line\", marker=\"o\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Average availability (probability of available)\")\n",
    "plt.title(\"Average availability by month\")\n",
    "plt.xticks(range(1, 13))\n",
    "plt.show()\n",
    "\n",
    "# Availability by day of week\n",
    "availability_by_dow = base_df.groupby(\"day_of_week\")[\"available_flag\"].mean()\n",
    "print(availability_by_dow)\n",
    "\n",
    "plt.figure()\n",
    "availability_by_dow.plot(kind=\"bar\")\n",
    "plt.xlabel(\"Day of week (0 = Mon, 6 = Sun)\")\n",
    "plt.ylabel(\"Average availability\")\n",
    "plt.title(\"Average availability by day of week\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdba9d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph listing characteristics vs availability\n",
    "\n",
    "## Price cleaning\n",
    "\n",
    "if \"price\" in base_df.columns:\n",
    "    # Clean price from strings like \"$120.00\"\n",
    "    base_df[\"price_clean\"] = (\n",
    "        base_df[\"price\"]\n",
    "        .astype(str)\n",
    "        .str.replace(\"[\\$,]\", \"\", regex=True)\n",
    "        .replace(\"\", pd.NA)\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "    print(base_df[\"price_clean\"].describe())\n",
    "\n",
    "    # Boxplot: price vs availability\n",
    "    plt.figure()\n",
    "    base_df.boxplot(column=\"price_clean\", by=\"available_flag\")\n",
    "    plt.xlabel(\"available_flag (0 = booked, 1 = available)\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.title(\"Price distribution by availability\")\n",
    "    plt.suptitle(\"\")  # remove automatic subtitle\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae30e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Room type vs availability\n",
    "\n",
    "if \"room_type\" in base_df.columns:\n",
    "    availability_by_room_type = base_df.groupby(\"room_type\")[\"available_flag\"].mean()\n",
    "    print(availability_by_room_type)\n",
    "\n",
    "    plt.figure()\n",
    "    availability_by_room_type.sort_values().plot(kind=\"barh\")\n",
    "    plt.xlabel(\"Average availability\")\n",
    "    plt.ylabel(\"Room type\")\n",
    "    plt.title(\"Availability by room type\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321dcdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bedrooms vs availability\n",
    "\n",
    "if \"bedrooms\" in base_df.columns:\n",
    "    availability_by_bedrooms = base_df.groupby(\"bedrooms\")[\"available_flag\"].mean()\n",
    "    print(availability_by_bedrooms)\n",
    "\n",
    "    plt.figure()\n",
    "    availability_by_bedrooms.sort_index().plot(kind=\"bar\")\n",
    "    plt.xlabel(\"Bedrooms\")\n",
    "    plt.ylabel(\"Average availability\")\n",
    "    plt.title(\"Availability by number of bedrooms\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a5713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Neighbourhood vs availability\n",
    "\n",
    "if \"neighbourhood\" in base_df.columns:\n",
    "    availability_by_neigh = (\n",
    "        base_df.groupby(\"neighbourhood\")[\"available_flag\"]\n",
    "        .mean()\n",
    "        .sort_values()\n",
    "    )\n",
    "    print(availability_by_neigh.head())\n",
    "    print(availability_by_neigh.tail())\n",
    "\n",
    "    # Only plot top 20 most/least available to avoid a huge plot\n",
    "    plt.figure()\n",
    "    availability_by_neigh.tail(20).plot(kind=\"barh\")\n",
    "    plt.xlabel(\"Average availability\")\n",
    "    plt.ylabel(\"Neighbourhood\")\n",
    "    plt.title(\"Top 20 neighbourhoods by availability\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c17c8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph host characteristics vs availability\n",
    "\n",
    "# Superhost vs availability\n",
    "if \"host_is_superhost\" in base_df.columns:\n",
    "    print(base_df[\"host_is_superhost\"].value_counts())\n",
    "\n",
    "    availability_by_superhost = base_df.groupby(\"host_is_superhost\")[\"available_flag\"].mean()\n",
    "    print(availability_by_superhost)\n",
    "\n",
    "    plt.figure()\n",
    "    availability_by_superhost.plot(kind=\"bar\")\n",
    "    plt.xlabel(\"host_is_superhost\")\n",
    "    plt.ylabel(\"Average availability\")\n",
    "    plt.title(\"Availability by superhost status\")\n",
    "    plt.show()\n",
    "\n",
    "# Host listings count vs availability\n",
    "if \"host_listings_count\" in base_df.columns:\n",
    "    correlation = base_df[[\"host_listings_count\", \"available_flag\"]].corr().iloc[0, 1]\n",
    "    print(\"Correlation between host_listings_count and availability_flag:\", correlation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3ea20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple review-based features\n",
    "\n",
    "## Aggregate reviews: number of reviews per listing\n",
    "reviews_agg = (\n",
    "    reviews_clean\n",
    "    .groupby(\"listing_id\")\n",
    "    .size()\n",
    "    .rename(\"num_reviews\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(reviews_agg.head())\n",
    "\n",
    "## Merge aggregated reviews into base_df\n",
    "base_df = base_df.merge(reviews_agg, on=\"listing_id\", how=\"left\")\n",
    "\n",
    "## Fill NaN num_reviews (listings with no reviews yet)\n",
    "base_df[\"num_reviews\"] = base_df[\"num_reviews\"].fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d724d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check relation between reviews and availability\n",
    "print(base_df[[\"num_reviews\", \"available_flag\"]].corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559d2c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bin number of reviews for plotting\n",
    "base_df[\"reviews_bin\"] = pd.cut(\n",
    "    base_df[\"num_reviews\"],\n",
    "    bins=[0, 1, 5, 10, 20, 50, 100, base_df[\"num_reviews\"].max()],\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "availability_by_reviews = (\n",
    "    base_df.groupby(\"reviews_bin\")[\"available_flag\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "print(availability_by_reviews)\n",
    "\n",
    "plt.figure()\n",
    "availability_by_reviews.plot(x=\"reviews_bin\", y=\"available_flag\", kind=\"bar\")\n",
    "plt.xlabel(\"Number of reviews (binned)\")\n",
    "plt.ylabel(\"Average availability\")\n",
    "plt.title(\"Availability by number of reviews\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1495f2f8",
   "metadata": {},
   "source": [
    "**Feature Construction and Final Dataset** \n",
    "\n",
    "In this step, we transform the merged dataset into a model-ready table. Our goal is to select and construct a set of features that are:\n",
    "Relevant to the prediction task (daily availability).\n",
    "Interpretable, so that we can reason about the model’s behavior.\n",
    "Structured (numeric or well-defined categorical), which makes them easy to use in standard machine-learning algorithms.\n",
    "Each row of the final dataset represents a (listing, date) pair, with:\n",
    "A binary target: whether the listing is available on that date.\n",
    "A set of calendar features (month, day of week).\n",
    "Property-level features (price, capacity, room type, bedrooms, neighbourhood, etc.).\n",
    "Host-level features (superhost status, number of listings, response/acceptance rates).\n",
    "Review-based features (e.g., number of reviews).\n",
    "\n",
    "1. Calendar-based features\n",
    "From the date variable we derive:\n",
    "month – to capture seasonality patterns (e.g., high season vs low season).\n",
    "day_of_week – to capture weekly patterns (weekend vs weekday behavior).\n",
    "These features help the model learn that availability is not uniform over time.\n",
    "\n",
    "2. Listing (property) features\n",
    "From listings_clean, we keep structural and economic attributes that plausibly affect demand and availability, for example:\n",
    "price_clean – cleaned numeric nightly price.\n",
    "accommodates, bedrooms, beds – capacity and size of the property.\n",
    "room_type, property_type – type of listing (entire home/shared room, apartment/house, etc.).\n",
    "neighbourhood, latitude, longitude – location information.\n",
    "minimum_nights, maximum_nights – booking constraints that may influence occupancy.\n",
    "These variables capture what the listing is, where it is, and how much it costs.\n",
    "\n",
    "3. Host features\n",
    "From host-related columns, we include characteristics that may influence guest trust and booking behavior, such as:\n",
    "host_is_superhost – indicator of host quality and reliability.\n",
    "host_listings_count – host experience and portfolio size.\n",
    "host_response_rate, host_acceptance_rate – responsiveness and likelihood of accepting bookings (converted from percentages to numeric values between 0 and 1, when available).\n",
    "These features allow the model to account for host behavior and reputation.\n",
    "\n",
    "4. Review-based features\n",
    "From the aggregated reviews, we include:\n",
    "num_reviews – the total number of reviews per listing (after merging the aggregated review data).\n",
    "This acts as a proxy for listing popularity and maturity in the market. Listings with many reviews may show different availability patterns than brand-new ones with zero reviews.\n",
    "(If additional review score columns are available, such as review_scores_rating, review_scores_cleanliness, etc., they can also be included as continuous quality indicators.)\n",
    "\n",
    "5. Building the final modeling table\n",
    "Finally, we:\n",
    "Select the subset of relevant features based on the criteria above.\n",
    "Clean and convert some variables (e.g., prices and percentages) to proper numeric types.\n",
    "Drop rows with missing values in critical features when necessary.\n",
    "This results in a compact, structured dataset that is ready to be encoded (for categorical variables) and used to train machine-learning models that predict daily availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bfdf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Make sure date is datetime\n",
    "if not pd.api.types.is_datetime64_any_dtype(base_df[\"date\"]):\n",
    "    base_df[\"date\"] = pd.to_datetime(base_df[\"date\"], errors=\"coerce\")\n",
    "\n",
    "# Calendar features\n",
    "base_df[\"month\"] = base_df[\"date\"].dt.month\n",
    "base_df[\"day_of_week\"] = base_df[\"date\"].dt.dayofweek  # 0 = Monday, 6 = Sunday\n",
    "\n",
    "# Clean price if needed\n",
    "if \"price_clean\" not in base_df.columns and \"price\" in base_df.columns:\n",
    "    base_df[\"price_clean\"] = (\n",
    "        base_df[\"price\"]\n",
    "        .astype(str)\n",
    "        .str.replace(\"[\\$,]\", \"\", regex=True)\n",
    "        .replace(\"\", pd.NA)\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "# Clean host response and acceptance rates\n",
    "for col in [\"host_response_rate\", \"host_acceptance_rate\"]:\n",
    "    if col in base_df.columns:\n",
    "        # Convert \"97%\" -> 0.97\n",
    "        base_df[col] = (\n",
    "            base_df[col]\n",
    "            .astype(str)\n",
    "            .str.strip()\n",
    "            .str.rstrip(\"%\")\n",
    "            .replace(\"\", pd.NA)\n",
    "        )\n",
    "        base_df[col] = base_df[col].astype(float) / 100.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0063ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "\n",
    "target_col = \"available_flag\"\n",
    "\n",
    "candidate_features = [\n",
    "    # calendar\n",
    "    \"month\",\n",
    "    \"day_of_week\",\n",
    "\n",
    "    # price / capacity\n",
    "    \"price_clean\",\n",
    "    \"accommodates\",\n",
    "    \"bedrooms\",\n",
    "    \"beds\",\n",
    "\n",
    "    # property / location\n",
    "    \"room_type\",\n",
    "    \"property_type\",\n",
    "    \"neighbourhood\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "\n",
    "    # host\n",
    "    \"host_is_superhost\",\n",
    "    \"host_listings_count\",\n",
    "    \"host_response_rate\",\n",
    "    \"host_acceptance_rate\",\n",
    "    \"minimum_nights\",\n",
    "    \"maximum_nights\",\n",
    "\n",
    "    # reviews\n",
    "    \"num_reviews\",\n",
    "]\n",
    "\n",
    "# Keep only features that actually exist in base_df\n",
    "features = [col for col in candidate_features if col in base_df.columns]\n",
    "\n",
    "print(\"Using the following features:\")\n",
    "print(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656fb66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean final df y clena NaNs\n",
    "\n",
    "# Build final modeling dataframe\n",
    "final_df = base_df[features + [target_col]].copy()\n",
    "\n",
    "# Define some critical numeric columns\n",
    "critical_cols = [c for c in [\"price_clean\", \"accommodates\"] if c in final_df.columns]\n",
    "\n",
    "# Drop rows with missing values in target or critical columns\n",
    "final_df = final_df.dropna(subset=critical_cols + [target_col])\n",
    "\n",
    "print(\"Final dataset shape:\", final_df.shape)\n",
    "final_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dc45c3",
   "metadata": {},
   "source": [
    "**Justification for Dropping Rows with Missing Values**\n",
    "\n",
    "We decided to drop rows containing missing values only in critical variables (e.g., price, accommodates, or the target variable). These fields represent essential structural attributes of each listing and cannot be reliably imputed without introducing noise or distorting the true characteristics of the property. Since our dataset is large, removing a small number of incomplete rows does not negatively affect model performance, and it avoids injecting artificial or incorrect information that could bias the predictive model. For non-critical fields (e.g., review counts or host response rates), we use more appropriate imputations such as zero or mean values when they reflect meaningful defaults."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
